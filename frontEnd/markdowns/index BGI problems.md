# 首页背景图爬虫遇到的问题

看到阮一峰大神的首页不错，还简单，不用花脑细胞和时间去折腾自己本来就没有的设计审美。

我知道的图片质量比较高的一个网站是[500px](https://500px.com)。决定就这个了。

## 做一个爬虫的原因

首先想到的就是写一个爬虫。折腾了一半，想起来，这么大的网站，应该有API的，就搜了一下，还真有。

但是折腾了官方API一天多之后，发现这个必须使用网页加web服务才可以，他每次开启都要认证，而且每次认证都要回调一个被认证者的一个有指定内容的指定网页。在我发现这个之后（半天过去了），尝试用node服务器改造这个（半天多）后无果，就决定自己写一个爬虫好了。

经过一个个验证之后，得到了500px网站的访问关键点，然后爬虫就好了。过滤了纵向的和宽高过低的图片~~虽然手机端因为`background-size: cover`的原因甚至看不到一丁点图片主题，那么没办法咯~~。

## 首页背景图逻辑

理想中的需求是，每次加载首页的时候，随机一张图片。图片左下角有个区域，有图片的500px的地址，图片的名字和作者，外加俩按钮，一个是喜欢一个是不喜欢。

具体实现：

1. 爬虫得到数据之后，过滤出自己想要的数据，然后统一打上一个`temp`的标签存到数据库。然后下载图片到`temp`文件夹。之所以下载图片，是因为这个网站在XX内时常打不开，虽然我这个VPS延迟高，但总算还是稳定的。~~坑就出现在这里~~

1. 每次打开首页的时候，发出一个请求，表示想要得到一张图片。
    1. 从数据库过滤标签为`temp`的图片，如果有，就随机一个发出去
    2. 如果没有，就找标签为`liked`的图片，如果有，随机一个发出去
    3.  如果上面两个都没有，就启动爬虫，爬取的信息存数据库，下载图片，然后从爬去的信息用随机一个发出去
    
1. 点击喜欢按钮的时候，把数据库里的这个数据的标签更新为`liked`，然后把图片从`temp`移动到`liked`
2. 点击不喜欢按钮的时候，从数据库和`temp`文件夹里删除这个文件和相关信息。并发送操作成功与否的信息给页面，页面选择报错或者是重新发出一个需要背景图的请求。

## 出现的问题

我选的页面是[编辑推荐](https://500px.com/editors)，这样质量比较可控。问题是图片每天只更新几张，我每次只爬第一页，50张图片左右。*首页喜欢/不喜欢过滤完之后，再下载的图片里，还是会有我不喜欢的*。

爬两到三次之后就出现了两个问题：
 - 每次爬取之后，对那些不喜欢的照片都要重新点击一次不喜欢，这样有种恍惚的感觉……虽然这个问题在当时设计的时候就已经考虑到了，觉得也没什么大不了的，就放过去了。
 - `temp`文件夹里有很多不喜欢的照片，但是数据库里没有这些图片的信息。

出现第二个问题的时候，我觉得这是一个大问题了。因为图片的体积可能会很大，半年就可能会吃掉我那只有20G的硬盘。必须要解决了。


## 解决方案


不过首先要说说为啥不用重复点击喜欢……。

因为我存储的主键是图片的ID，ID来源于500px，这个不可能会重复~~吧？~~。而且使用了`mongoose`，重复的主键进行存储的时候，是报错的。`catch`掉这个错误就完事了。也就是说我已经喜欢的，不会被重复存储到数据库。

解决的方案现在只想到了一个：

点击删除按钮的时候，不删除数据库的信息，只是给这个信息添加一个新的标签（比如`dislike`），然后删除磁盘上的文件。下次再有不喜欢的图片被爬到进行存储的时候，只会报错就完事了。

这样的代价是，数据库里会有很多垃圾数据。

## 最后

其实这里还有一个问题。

每次爬到的信息强制存储到数据库，用数据库去重之后到信息去下载新的图片。就会出现有的文件下载失败，这样首页拿到的背景图就是一个不存在的图片，或者是一张坏掉的图片。这个也好解决啦，就是遇到下载失败的，从数据库删除这个图片的信息，就不去实现重试下载的机制了，这个更折腾了。

因为服务器在美国，所以这种情况也很少见，我见过这个VPS下载美国的资源的时候，飙到了70MB/s……

~~到这里才发现问题这么容易就解决了，还是写出来好点，如果大脑缓存空减少到话~~